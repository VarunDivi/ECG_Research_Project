{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model for predicting Sex from ECGs\n",
    "import tensorflow as tf # Make sure that python interpreter is 3.9.13 Global env\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wfdb\n",
    "import ast\n",
    "import ecg_plot\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "### Loading raw data into mutable Datframes\n",
    "ptb = pd.read_csv('../data/ptbxl_database.csv')\n",
    "ptb.head()\n",
    "len(ptb)\n",
    "def load_raw_data(df, sampling_rate, path):\n",
    "    data = [wfdb.rdsamp(path+f) for f in df.filename_lr]\n",
    "    data = np.array([signal for signal, meta in data])\n",
    "    return data\n",
    "sampling_rate=100\n",
    "# load and convert annotation data\n",
    "Y = pd.read_csv('../data/ptbxl_database.csv', index_col='ecg_id')\n",
    "Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "\n",
    "# Load raw signal data\n",
    "X = load_raw_data(Y, sampling_rate, '../data/')\n",
    "ecg_plot.plot_12(tf.transpose(X, (0,2,1))[0], sample_rate=100)\n",
    "\n",
    "# Load scp_statements.csv for diagnostic aggregation\n",
    "agg_df = pd.read_csv('../data/scp_statements.csv', index_col=0)\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "def aggregate_diagnostic(y_dic):\n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "    return list(set(tmp))\n",
    "\n",
    "\n",
    "# Apply diagnostic superclass\n",
    "Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_diagnostic)\n",
    "\n",
    "agg_df\n",
    "\n",
    "Y_pd = pd.DataFrame(Y)\n",
    "Y_pd\n",
    "### Visualizing the Data\n",
    "# Distribution of Male and Female ECGs\n",
    "uniques, counts = np.unique(Y_pd.sex, return_counts=True)\n",
    "plt.bar(uniques, counts)\n",
    "for i in range(len(uniques)):\n",
    "    plt.text(i, counts[i], str(counts[i]), ha='center', va='bottom')\n",
    "    plt.text(i, i, str(i), ha='center', va='bottom', color = \"white\")\n",
    "plt.title(\"Distribution of Sex\")\n",
    "diag_uniques, diag_counts = np.unique(Y_pd.diagnostic_superclass, return_counts=True)\n",
    "temp = [str(i) for i in diag_uniques]\n",
    "plt.bar(temp, diag_counts, width = 0.5)\n",
    "for i in range(len(diag_uniques)):\n",
    "    plt.text(i, diag_counts[i], str(diag_counts[i]), ha='center', va='bottom', size = 9, rotation = 60)\n",
    "\n",
    "plt.xticks(rotation = 90)\n",
    "plt.ylim(0, max(diag_counts) + max(diag_counts)*0.15)\n",
    "plt.title(\"Distribution of Diagnostic Superclasses\")\n",
    "* NORM: Normal ECG\n",
    "* MI: Myocardial Infarction\n",
    "* STTC: ST/T Change\n",
    "* CD: Conduction Disturbance\n",
    "* HYP: Hypertrophy\n",
    "\n",
    "\n",
    "To accurately predict the diagnostic superclass, much more data cleaning is required. \n",
    "* I will either need to trim the superclass list or spread out the concatenated data and one hot encode it. \n",
    "### Preprocessing\n",
    "# Normalization\n",
    "# Compute mean and standard deviation along axis 1 and 2\n",
    "X_mean = np.mean(X, axis=(-1), keepdims=True)\n",
    "X_std = np.std(X, axis=(-1), keepdims= True)\n",
    "\n",
    "X_mean.shape\n",
    "# Normalize data by subtracting mean and dividing by standard deviation\n",
    "X_norm = (X - X_mean) / X_std\n",
    "X_norm.shape\n",
    "\n",
    "X_norm[(1,2,3),:,:]\n",
    "\n",
    "# Split data into train and test\n",
    "test_fold =10\n",
    "X_train = X_norm[(Y.strat_fold != test_fold)]\n",
    "y_train = Y[Y.strat_fold != test_fold].sex\n",
    "\n",
    "X_test = X_norm[(Y.strat_fold == test_fold)]\n",
    "y_test = Y[Y.strat_fold == test_fold].sex\n",
    "\n",
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)\n",
    "\n",
    "y_train = y_train.idxmax(axis = 1).to_numpy()\n",
    "y_test = y_test.idxmax(axis = 1).to_numpy()\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "type(X_train)\n",
    "# Evaluating data distribution\n",
    "uniques, counts = np.unique(pd.DataFrame(y_train), return_counts=True)\n",
    "plt.bar(uniques, counts)\n",
    "for i in range(len(uniques)):\n",
    "    plt.text(i, counts[i], str(counts[i]), ha='center', va='bottom')\n",
    "    plt.text(i, i, str(i), ha='center', va='bottom', color = \"white\")\n",
    "plt.title(\"Distribution of Sex\")\n",
    "# # Reshaping for ecg_sex_ecg_sex_ecg_sex_ecg_sex_ecg_sex_ecg_sex_model_8_8_8_8_8_8\n",
    "# X_train = tf.reshape(X_train, (19601, 1000, 12,1))\n",
    "# X_test = tf.reshape(X_test, (2198, 1000, 12,1))\n",
    "# Model Creation\n",
    "### Model 1\n",
    "* Few Hidden layers\n",
    "* Deafault 0.001 learning rate\n",
    "* 2 layers of spatial analysis\n",
    "* 1 Fully connected layer\n",
    "* Relu and Sigmoid activations\n",
    "tf.debugging.disable_traceback_filtering\n",
    "# Random Seed\n",
    "tf.random.set_seed(13)\n",
    "\n",
    "# Creating the model\n",
    "\n",
    "ecg_sex_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters = 10, kernel_size = 7, strides = 2, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2, strides = 1, padding = \"valid\"),\n",
    "    tf.keras.layers.Conv1D(filters = 25, kernel_size = 4, strides = 1, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2, strides = 1, padding = \"valid\"),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(25, activation= 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation= 'sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compiling the model\n",
    "\n",
    "ecg_sex_model.compile(loss = tf.keras.losses.binary_crossentropy,\n",
    "                      optimizer = tf.keras.optimizers.Adam(learning_rate= 0.001),\n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "# Learning rate scheduler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Fitting the model\n",
    "\n",
    "history = ecg_sex_model.fit(X_train, y_train, epochs = 10, validation_data = (X_test, y_test))\n",
    "### Model 2\n",
    "* Modification of the number of neurons. \n",
    "* Adjusted learning rate slighlty\n",
    "tf.debugging.disable_traceback_filtering\n",
    "# Random Seed\n",
    "tf.random.set_seed(13)\n",
    "\n",
    "# Creating the model\n",
    "\n",
    "ecg_sex_model_2 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters = 32, kernel_size = 7, strides = 3, padding = \"valid\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2, strides = 1, padding = \"valid\"),\n",
    "    tf.keras.layers.Conv1D(filters = 64, kernel_size = 3, strides = 1, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(15, activation= 'relu'),\n",
    "    tf.keras.layers.Dense(1, activation= 'sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compiling the model\n",
    "\n",
    "ecg_sex_model_2.compile(loss = tf.keras.losses.binary_crossentropy,\n",
    "                      optimizer = tf.keras.optimizers.Adam(learning_rate= 0.0015),\n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "# Learning rate scheduler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Fitting the model\n",
    "\n",
    "history_2 = ecg_sex_model_2.fit(X_train, y_train, epochs = 8, validation_data = (X_test, y_test))\n",
    "### Model 3\n",
    "* Additional spatial layer\n",
    "\n",
    "\n",
    "**Key Issues at this time**\n",
    "* The model appeared to be over fitting to the training data evidenced by the varying accuracies between training and testing\n",
    "tf.debugging.disable_traceback_filtering\n",
    "# Random Seed\n",
    "tf.random.set_seed(13)\n",
    "\n",
    "# Creating the model\n",
    "\n",
    "ecg_sex_model_3 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters = 32, kernel_size = 7, strides = 4, padding = \"valid\", activation='relu'),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=4, strides = 1, padding = \"valid\"),\n",
    "    tf.keras.layers.Conv1D(filters = 64, kernel_size = 6, strides = 3, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=4, strides = 1, padding = \"valid\"),\n",
    "    tf.keras.layers.Conv1D(filters = 96, kernel_size = 4, strides = 2, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2, strides = 1, padding = \"valid\"),\n",
    "    tf.keras.layers.Dense(25, activation= 'relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(1, activation= 'sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compiling the model\n",
    "\n",
    "ecg_sex_model_3.compile(loss = tf.keras.losses.binary_crossentropy,\n",
    "                      optimizer = tf.keras.optimizers.Adam(learning_rate= 0.0015),\n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "# Learning rate scheduler\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Fitting the model\n",
    "\n",
    "history_3 = ecg_sex_model_3.fit(X_train, y_train, epochs = 10, validation_data = (X_test, y_test))\n",
    "### Model 4\n",
    "* Implemented learning rate scheduler callback\n",
    "* Implemented early stop callback\n",
    "* Additional spatial layer\n",
    "* Weaved in batch normalization\n",
    "* Implemented weight droppout\n",
    "tf.debugging.disable_traceback_filtering\n",
    "# Random Seed\n",
    "tf.random.set_seed(13)\n",
    "\n",
    "# Creating the model\n",
    "\n",
    "ecg_sex_model_4 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters = 32, kernel_size = 7, strides = 4, padding = \"valid\", activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=4, strides = 1, padding = \"valid\"),\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters = 48, kernel_size = 6, strides = 3, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=3, strides = 1, padding = \"valid\"),\n",
    "    tf.keras.layers.Dropout(0.2, seed = 13),\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters = 64, kernel_size = 4, strides = 2, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2, strides = 1, padding = \"valid\"),\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters = 96, kernel_size = 3, strides = 1, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2, strides = 1, padding = \"valid\"),\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "\n",
    "    tf.keras.layers.Dense(64, activation= 'relu'),\n",
    "    tf.keras.layers.Dropout(0.2, seed = 13),\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dense(1, activation= 'sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compiling the model\n",
    "\n",
    "ecg_sex_model_4.compile(loss = tf.keras.losses.binary_crossentropy,\n",
    "                      optimizer = tf.keras.optimizers.Adam(learning_rate= 0.001),\n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "# Learning rate scheduler\n",
    "early_stopper = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', min_delta= 0.01,patience = 4, baseline= 0.75)\n",
    "\n",
    "\n",
    "\n",
    "# Fitting the model\n",
    "\n",
    "history_4 = ecg_sex_model_4.fit(X_train, y_train, epochs = 12, validation_data = (X_test, y_test), callbacks = early_stopper)\n",
    "\n",
    "### Model 5\n",
    "* 5 spatial layers each with their own batch normalization\n",
    "* Modified learning rate\n",
    "* Implemented Lasso L1 regularizer. \n",
    "* Early stopper in place\n",
    "tf.debugging.disable_traceback_filtering\n",
    "# Random Seed\n",
    "tf.random.set_seed(13)\n",
    "tf.keras.backend.set_image_data_format('channels_first')\n",
    "\n",
    "\n",
    "# Creating the model\n",
    "\n",
    "ecg_sex_model_5 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters = 32, kernel_size = 8, strides = 4, padding = \"valid\", activation='relu', input_shape= (1000, 12)),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=4, strides = 1, padding = \"valid\"),\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters = 48, kernel_size = 7, strides = 3, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2, strides = 1, padding = \"valid\"),\n",
    "    tf.keras.layers.Dropout(0.2, seed = 13),\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters = 64, kernel_size = 5, strides = 2, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2, strides = 1, padding = \"valid\"),\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters = 96, kernel_size = 4, strides = 1, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2, strides = 1, padding = \"valid\"),\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters = 128, kernel_size = 3, strides = 1, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2, strides = 1, padding = \"valid\"),\n",
    "\n",
    "\n",
    "    tf.keras.layers.Dense(64, activation= 'relu', kernel_regularizer='l1'),\n",
    "    tf.keras.layers.Dropout(0.2, seed = 13),\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dense(1, activation= 'sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compiling the model\n",
    "\n",
    "ecg_sex_model_5.compile(loss = tf.keras.losses.binary_crossentropy,\n",
    "                      optimizer = tf.keras.optimizers.Adam(learning_rate= 0.0009),\n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "# Learning rate scheduler\n",
    "early_stopper = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', min_delta= 0.01,patience = 4, baseline= 0.75)\n",
    "#lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: (0.0008) * 10**(epoch/20))\n",
    "\n",
    "\n",
    "\n",
    "# Fitting the model\n",
    "\n",
    "history_5 = ecg_sex_model_5.fit(X_train, y_train, epochs = 12, validation_data = (X_test, y_test), callbacks = (early_stopper))\n",
    "### Model 6\n",
    "* Wanted to see if model's performance was proportional to training time\n",
    "* Doubled the epochs and disabled the early stopper\n",
    "\n",
    "\n",
    "**Take aways**\n",
    "* The model's training accuracy consistently grew with epochs\n",
    "* The model's testing accuracy fluctuated and plateaued around 0.8\n",
    "* The number of epochs has little effect on testing accuracy when the model overfits.\n",
    "tf.debugging.disable_traceback_filtering\n",
    "# Random Seed\n",
    "tf.random.set_seed(13)\n",
    "\n",
    "# Creating the model\n",
    "\n",
    "ecg_sex_model_6 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters = 32, kernel_size = 8, strides = 4, padding = \"valid\", activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=4, strides = 1, padding = \"valid\"),\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters = 64, kernel_size = 7, strides = 3, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2, strides = 1, padding = \"valid\"),\n",
    "    tf.keras.layers.Dropout(0.2, seed = 13),\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters = 96, kernel_size = 5, strides = 2, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2, strides = 1, padding = \"valid\"),\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters = 128, kernel_size = 4, strides = 1, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2, strides = 1, padding = \"valid\"),\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters = 160, kernel_size = 3, strides = 1, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2, strides = 1, padding = \"valid\"),\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "\n",
    "    tf.keras.layers.Dense(64, activation= 'relu', kernel_regularizer='l1'),\n",
    "    tf.keras.layers.Dropout(0.2, seed = 13),\n",
    "\n",
    "    tf.keras.layers.Dense(1, activation= 'sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compiling the model\n",
    "\n",
    "ecg_sex_model_6.compile(loss = tf.keras.losses.binary_crossentropy,\n",
    "                      optimizer = tf.keras.optimizers.Adam(learning_rate= 0.0009),\n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "# Learning rate scheduler\n",
    "early_stopper = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', min_delta= 0.01,patience = 4, baseline= 0.75)\n",
    "#lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: (0.0008) * 10**(epoch/20))\n",
    "\n",
    "\n",
    "\n",
    "# Fitting the model\n",
    "\n",
    "history_6 = ecg_sex_model_6.fit(X_train, y_train, epochs = 20, validation_data = (X_test, y_test))\n",
    "\n",
    "### Model 7\n",
    "* 8 spatial layers\n",
    "* 1 temporal layer\n",
    "* 2 Fully connected layer\n",
    "* https://www.ahajournals.org/doi/full/10.1161/CIRCEP.119.007284\n",
    "tf.debugging.disable_traceback_filtering\n",
    "tf.config.list_physical_devices('GPU')\n",
    "# Random Seed\n",
    "tf.random.set_seed(13)\n",
    "\n",
    "# Creating the model\n",
    "\n",
    "ecg_sex_model_7 = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv1D(filters = 16, kernel_size = 7, strides = 1, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2, strides = 1, padding = \"valid\"),\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters = 16, kernel_size = 5, strides = 1, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=5, strides = 1, padding = \"valid\"),\n",
    "    tf.keras.layers.Dropout(0.2, seed = 13),\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters = 32, kernel_size = 5, strides = 1, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2, strides = 1, padding = \"valid\"),\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters = 32, kernel_size = 5, strides = 1, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=4, strides = 1, padding = \"valid\"),\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters = 64, kernel_size = 3, strides = 1, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2, strides = 1, padding = \"valid\"),\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters = 64, kernel_size = 3, strides = 1, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2, strides = 1, padding = \"valid\"),\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters = 64, kernel_size = 3, strides = 1, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2, strides = 1, padding = \"valid\"),\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters = 64, kernel_size = 3, strides = 1, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2, strides = 1, padding = \"valid\"),\n",
    "\n",
    "    tf.keras.layers.Conv1D(filters = 128, kernel_size = 12, strides = 1, padding = \"valid\", activation = 'relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.MaxPool1D(pool_size=2, strides = 1, padding = \"valid\"),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    tf.keras.layers.Dense(128, activation= 'relu', kernel_regularizer='l1'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2, seed = 13),\n",
    "\n",
    "\n",
    "    tf.keras.layers.Dense(64, activation= 'relu', kernel_regularizer='l1'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2, seed = 13),\n",
    "\n",
    "    tf.keras.layers.Dense(1, activation= 'sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compiling the model\n",
    "\n",
    "ecg_sex_model_7.compile(loss = tf.keras.losses.binary_crossentropy,\n",
    "                      optimizer = tf.keras.optimizers.Adam(learning_rate= .0001),\n",
    "                      metrics = ['accuracy'])\n",
    "\n",
    "# Learning rate scheduler\n",
    "early_stopper = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy', min_delta= 0.01,patience = 5)\n",
    "lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: (0.0008) * 10**(epoch/20))\n",
    "\n",
    "\n",
    "\n",
    "# Fitting the model\n",
    "\n",
    "history_7 = ecg_sex_model_7.fit(X_train, y_train, epochs = 25, validation_data = (X_test, y_test))\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Note: The following confusion matrix code is a remix of Scikit-Learn's \n",
    "# plot_confusion_matrix function - https://scikit-learn.org/stable/modules/generated/sklearn.metrics.plot_confusion_matrix.html\n",
    "# and Made with ML's introductory notebook - https://github.com/GokuMohandas/MadeWithML/blob/main/notebooks/08_Neural_Networks.ipynb \n",
    "import itertools\n",
    "\n",
    "figsize = (10, 10)\n",
    "\n",
    "def make_confusion_matrix(X_test, y_test, classes, model, figsize=(18,18), text_size = 15):\n",
    "    # Create the confusion matrix\n",
    "    y_prob = model.predict(X_test)\n",
    "    y_pred =np.squeeze(np.where(y_prob >= 0.5, 1, 0))\n",
    "    cm = confusion_matrix(y_test, tf.round(y_pred))\n",
    "    cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis] # normalize it\n",
    "    n_classes = cm.shape[0]\n",
    "\n",
    "    # Let's prettify it\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    # Create a matrix plot\n",
    "    cax = ax.matshow(cm, cmap=plt.cm.Blues) # https://matplotlib.org/3.2.0/api/_as_gen/matplotlib.axes.Axes.matshow.html\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Create classes\n",
    "    if classes:\n",
    "        labels = classes\n",
    "    else:\n",
    "        labels = np.arange(cm.shape[0])\n",
    "\n",
    "    # Label the axes\n",
    "    ax.set(title=(str(model.name) + \" for Confusion Matrix\"),\n",
    "        xlabel=\"Predicted label\",\n",
    "        ylabel=\"True label\",\n",
    "        xticks=np.arange(n_classes),\n",
    "        yticks=np.arange(n_classes),\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels)\n",
    "\n",
    "    # Set x-axis labels to bottom\n",
    "    ax.xaxis.set_label_position(\"bottom\")\n",
    "    ax.xaxis.tick_bottom()\n",
    "\n",
    "    # Adjust label size\n",
    "    ax.xaxis.label.set_size(20)\n",
    "    ax.yaxis.label.set_size(20)\n",
    "    ax.title.set_size(20)\n",
    "\n",
    "    # Set threshold for different colors\n",
    "    threshold = (cm.max() + cm.min()) / 2.\n",
    "\n",
    "    # Plot the text on each cell\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, f\"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)\",\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > threshold else \"black\",\n",
    "                size=10)\n",
    "### Visualization of data\n",
    "y_prob = ecg_sex_model_6.predict(X_test)\n",
    "y_pred =np.squeeze(np.where(y_prob >= 0.5, 1, 0))\n",
    "\n",
    "\n",
    "class_name = ['Male', 'Female']\n",
    "make_confusion_matrix(X_test, y_test, model = ecg_sex_model_6, classes = class_name)\n",
    "\n",
    "\n",
    "# Visualizing the ECGs with model interpretation\n",
    "* External resources:\n",
    "    * https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2760216/\n",
    "from random import choice\n",
    "\n",
    "def visualize(y_test, X_test, model):\n",
    "    class_names  = ['Male', 'Female']\n",
    "    y_prob = model.predict(X_test)\n",
    "    y_pred =np.squeeze(np.where(y_prob >= 0.5, 1, 0))\n",
    "    for i in range(4):\n",
    "        ind = choice(range(1, len(X_test)))\n",
    "        plot_title = (\"Actual: \" + class_names[y_test[ind]] + \"    Predicted: \" + class_names[y_pred[ind]])\n",
    "        ecg_plot.plot_1(tf.transpose(X, (0,2,1))[ind][4], sample_rate=100, title = plot_title + \"   aVL focus\")\n",
    "\n",
    "visualize(y_test, X_test, ecg_sex_model_6)\n",
    "from random import choice\n",
    "\n",
    "def visualize(y_test, X_test, model):\n",
    "    class_names  = ['Male', 'Female']\n",
    "    y_prob = model.predict(X_test)\n",
    "    y_pred =np.squeeze(np.where(y_prob >= 0.5, 1, 0))\n",
    "    for i in range(4):\n",
    "        ind = choice(range(1, len(X_test)))\n",
    "        plot_title = (\"Actual: \" + class_names[y_test[ind]] + \"    Predicted: \" + class_names[y_pred[ind]])\n",
    "        ecg_plot.plot_1(tf.transpose(X, (0,2,1))[ind][4], sample_rate=100, title = plot_title + \"   aVL focus\")\n",
    "\n",
    "visualize(y_test, X_test, ecg_sex_model_6)\n",
    "\n",
    "### Conclusions\n",
    "* Attempt to train on the 500hz data set\n",
    "* Use a cloud computing system to train larger models such as Google Collab. \n",
    "* Fine tune an existing high performance model such as ResNet. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
