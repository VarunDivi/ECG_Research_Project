{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf # Models ran in venv python 3.9.16 with GPU computing support\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wfdb\n",
    "import ast\n",
    "import ecg_plot\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    ### Loading raw data into mutable Datframes\n",
    "    ptb = pd.read_csv('../data/ptbxl_database.csv')\n",
    "    def load_raw_data(df, sampling_rate, path):\n",
    "        if(sampling_rate == 100):\n",
    "            data = [wfdb.rdsamp(path+f) for f in df.filename_lr]\n",
    "        else:\n",
    "            data = [wfdb.rdsamp(path+f) for f in df.filename_hr]\n",
    "        data = np.array([signal for signal, meta in data])\n",
    "        return data\n",
    "    \n",
    "    # load and convert annotation data\n",
    "    Y = pd.read_csv('../data/ptbxl_database.csv', index_col='ecg_id')\n",
    "    Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "    # Load raw signal data\n",
    "    X = load_raw_data(Y, sr, '../data/')\n",
    "\n",
    "    # Load scp_statements.csv for diagnostic aggregation\n",
    "    agg_df = pd.read_csv('../data/scp_statements.csv', index_col=0)\n",
    "    agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "    def aggregate_diagnostic(y_dic):\n",
    "        tmp = []\n",
    "        for key in y_dic.keys():\n",
    "            if key in agg_df.index:\n",
    "                tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "        return list(set(tmp))\n",
    "\n",
    "\n",
    "    # Apply diagnostic superclass\n",
    "    Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "def normalize(X, shape = False):\n",
    "    # Compute mean and standard deviation along axis 1 and 2\n",
    "    X_mean = np.mean(X)\n",
    "    X_std = np.std(X)\n",
    "\n",
    "    if(shape):\n",
    "        print(X.shape)\n",
    "    # Normalize data by subtracting mean and dividing by standard deviation\n",
    "    return ((X - X_mean) / X_std)\n",
    "\n",
    "#____________________________________________________________________________________#\n",
    "\n",
    "bld = 0.5\n",
    "def baseline_drift(X, baseline, range = 0):\n",
    "    bld_range = (baseline-range, baseline+range)\n",
    "    random_shifts = np.random.uniform(bld_range[0], bld_range[1], size = X.shape)\n",
    "    return X + random_shifts\n",
    "\n",
    "#____________________________________________________________________________________#\n",
    "\n",
    "# Define the filter parameters\n",
    "fs = 100  # Sampling frequency (Hz)\n",
    "lowcut = 0.5  # Lower cutoff frequency (Hz)\n",
    "highcut = 40.0  # Higher cutoff frequency (Hz)\n",
    "filter_order = 4  # Filter order\n",
    "\n",
    "def bandpass(X, fs, lowcut, highcut, filter_order):\n",
    "    # Apply bandpass filter to each channel\n",
    "    filtered_data = np.zeros_like(X)\n",
    "    for i in range(X.shape[2]):\n",
    "        for j in range(X.shape[0]):\n",
    "            b, a = signal.butter(filter_order, [lowcut, highcut], fs=fs, btype='band', output='ba')\n",
    "            filtered_data[j, :, i] = signal.filtfilt(b, a, X[j, :, i])\n",
    "\n",
    "    # Print the shape of the filtered data\n",
    "    return filtered_data\n",
    "\n",
    "#____________________________________________________________________________________#\n",
    "\n",
    "def da_apply(X, functions, shape = False):\n",
    "    X_final = X.copy()\n",
    "\n",
    "    # Applys DA Augments in specified order\n",
    "    for func_dict in functions:\n",
    "        func = func_dict['func']\n",
    "        if(func_dict['params'] == None):\n",
    "            X_final = func(X_final)     \n",
    "        else:\n",
    "            params = func_dict['params']\n",
    "            X_final = func(X_final, *params)  \n",
    "\n",
    "    if(shape == True):\n",
    "        print(X_final.shape)\n",
    "\n",
    "    return X_final\n",
    "\n",
    "#func_dict = [{'func': normalize, 'params': [None]}]\n",
    "\n",
    "#func_dict = [{'func': baseline_drift, 'params': [0,0.05]}]\n",
    "\n",
    "# func_dict =[{'func': normalize, 'params': [None]},\n",
    "#             {'func': bandpass, 'params': [100, 0.5, 10, 3]}, # 100, 0.5, 10, 3\n",
    "#             {'func': baseline_drift, 'params': [0,0.075]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    func_dict =[{'func': normalize, 'params': [None]},  # Normalizing across the entire data set instead of by lead\n",
    "                {'func': baseline_drift, 'params': [0,0.075]}]  # I found that simulating a 0.075 drift works best\n",
    "\n",
    "    X_final = da_apply(X, func_dict) # If you want to experiment with data shape more, use a smaller data size. Subset X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((17418, 1000, 12), (17418,), (2183, 1000, 12), (2183,), (2198, 1000, 12), (2198,))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    # Split data into train and test\n",
    "    test_fold =10\n",
    "    val_fold = 9\n",
    "\n",
    "    def tvt_split(X, Y, val_fold, test_fold, shape = False):\n",
    "        X_train = X[(Y.strat_fold != test_fold) & (Y.strat_fold != val_fold)]\n",
    "        y_train = Y[(Y.strat_fold != test_fold) & (Y.strat_fold != val_fold)].age\n",
    "\n",
    "        X_val = X[Y.strat_fold == val_fold]\n",
    "        y_val = Y[Y.strat_fold == val_fold].age\n",
    "\n",
    "        X_test = X[(Y.strat_fold == test_fold)]\n",
    "        y_test = Y[Y.strat_fold == test_fold].age\n",
    "\n",
    "        y_train = pd.get_dummies(y_train)\n",
    "        y_val = pd.get_dummies(y_val)\n",
    "        y_test = pd.get_dummies(y_test)\n",
    "\n",
    "        y_train = y_train.idxmax(axis = 1).to_numpy()\n",
    "        y_val = y_val.idxmax(axis = 1).to_numpy()\n",
    "        y_test = y_test.idxmax(axis = 1).to_numpy()\n",
    "\n",
    "        rX_train = X_train[(y_train < 89) & (y_train >= 18)] # Additional filtering of patients older than 89 and younger than 18\n",
    "        ry_train = y_train[(y_train < 89) & (y_train >= 18)]\n",
    "\n",
    "        rX_val = X_val[(y_val < 89) & (y_val >= 18)]\n",
    "        ry_val = y_val[(y_val < 89) & (y_val >= 18)]\n",
    "\n",
    "        rX_test = X_test[(y_test < 89) & (y_test >= 18)]\n",
    "        ry_test = y_test[(y_test < 89) & (y_test >= 18)]\n",
    "\n",
    "        if(shape == True):\n",
    "            print((X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape))\n",
    "\n",
    "        return rX_train, ry_train, rX_val, ry_val, rX_test, ry_test\n",
    "\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = tvt_split(X_final, Y, val_fold, test_fold, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_age_model_2 = tf.keras.models.load_model(\"../saved_models/100hz/age_models/model_1.h5\")\n",
    "ecg_sex_model_2 = tf.keras.models.load_model(\"../saved_models/100hz/sex_models/model_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    age_temp = ecg_age_model_2(tf.convert_to_tensor(X_test))\n",
    "\n",
    "predicted_age_unsorted = np.asarray(tf.squeeze(age_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.377134660079085"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error,accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "mean_absolute_error(y_test, predicted_age_unsorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-Squared\n",
    "* Metric for how well the model explains variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6122021713525028"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, predicted_age_unsorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sex Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((17418, 1000, 12), (17418,), (2183, 1000, 12), (2183,), (2198, 1000, 12), (2198,))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    # Split data into train and test\n",
    "    test_fold =10\n",
    "    val_fold = 9\n",
    "\n",
    "    def tvt_split(X, Y, val_fold, test_fold, shape = False):\n",
    "        X_train = X[(Y.strat_fold != test_fold) & (Y.strat_fold != val_fold)]\n",
    "        y_train = Y[(Y.strat_fold != test_fold) & (Y.strat_fold != val_fold)].sex\n",
    "\n",
    "        X_val = X[Y.strat_fold == val_fold]\n",
    "        y_val = Y[Y.strat_fold == val_fold].sex\n",
    "\n",
    "        X_test = X[(Y.strat_fold == test_fold)]\n",
    "        y_test = Y[Y.strat_fold == test_fold].sex\n",
    "\n",
    "        y_train = pd.get_dummies(y_train)\n",
    "        y_val = pd.get_dummies(y_val)\n",
    "        y_test = pd.get_dummies(y_test)\n",
    "\n",
    "        y_train = y_train.idxmax(axis = 1).to_numpy()\n",
    "        y_val = y_val.idxmax(axis = 1).to_numpy()\n",
    "        y_test = y_test.idxmax(axis = 1).to_numpy()\n",
    "\n",
    "        if(shape == True):\n",
    "            print((X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape))\n",
    "\n",
    "        return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "    sex_X_train, sex_y_train, sex_X_val, sex_y_val, sex_X_test, sex_y_test = tvt_split(X_final, Y, val_fold, test_fold, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    sex_temp = ecg_sex_model_2(tf.convert_to_tensor(sex_X_test))\n",
    "    predicted_sex_prob = np.asarray(tf.squeeze(sex_temp))\n",
    "    predicted_sex = np.where((np.squeeze(np.where(predicted_sex_prob >= 0.50, 1, 0))) == 1, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC AUC Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8861277587361359"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.sex.values\n",
    "predicted_sex\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(sex_y_test, predicted_sex_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
