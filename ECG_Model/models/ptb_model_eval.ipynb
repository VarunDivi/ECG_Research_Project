{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf # Models ran in venv python 3.9.16 with GPU computing support\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wfdb\n",
    "import ast\n",
    "import ecg_plot\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    ### Loading raw data into mutable Datframes\n",
    "    ptb = pd.read_csv('../data/ptbxl_database.csv')\n",
    "    def load_raw_data(df, sampling_rate, path):\n",
    "        if(sampling_rate == 100):\n",
    "            data = [wfdb.rdsamp(path+f) for f in df.filename_lr]\n",
    "        else:\n",
    "            data = [wfdb.rdsamp(path+f) for f in df.filename_hr]\n",
    "        data = np.array([signal for signal, meta in data])\n",
    "        return data\n",
    "    \n",
    "    # load and convert annotation data\n",
    "    Y = pd.read_csv('../data/ptbxl_database.csv', index_col='ecg_id')\n",
    "    Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "    # Load raw signal data\n",
    "    X = load_raw_data(Y, sr, '../data/')\n",
    "\n",
    "    # Load scp_statements.csv for diagnostic aggregation\n",
    "    agg_df = pd.read_csv('../data/scp_statements.csv', index_col=0)\n",
    "    agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "    def aggregate_diagnostic(y_dic):\n",
    "        tmp = []\n",
    "        for key in y_dic.keys():\n",
    "            if key in agg_df.index:\n",
    "                tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "        return list(set(tmp))\n",
    "\n",
    "\n",
    "    # Apply diagnostic superclass\n",
    "    Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "\n",
    "def normalize(X, shape = False):\n",
    "    # Compute mean and standard deviation along axis 1 and 2\n",
    "    X_mean = np.mean(X)\n",
    "    X_std = np.std(X)\n",
    "\n",
    "    if(shape):\n",
    "        print(X.shape)\n",
    "    # Normalize data by subtracting mean and dividing by standard deviation\n",
    "    return ((X - X_mean) / X_std)\n",
    "\n",
    "#____________________________________________________________________________________#\n",
    "\n",
    "bld = 0.5\n",
    "def baseline_drift(X, baseline, range = 0):\n",
    "    bld_range = (baseline-range, baseline+range)\n",
    "    random_shifts = np.random.uniform(bld_range[0], bld_range[1], size = X.shape)\n",
    "    return X + random_shifts\n",
    "\n",
    "#____________________________________________________________________________________#\n",
    "\n",
    "# Define the filter parameters\n",
    "fs = 100  # Sampling frequency (Hz)\n",
    "lowcut = 0.5  # Lower cutoff frequency (Hz)\n",
    "highcut = 40.0  # Higher cutoff frequency (Hz)\n",
    "filter_order = 4  # Filter order\n",
    "\n",
    "def bandpass(X, fs, lowcut, highcut, filter_order):\n",
    "    # Apply bandpass filter to each channel\n",
    "    filtered_data = np.zeros_like(X)\n",
    "    for i in range(X.shape[2]):\n",
    "        for j in range(X.shape[0]):\n",
    "            b, a = signal.butter(filter_order, [lowcut, highcut], fs=fs, btype='band', output='ba')\n",
    "            filtered_data[j, :, i] = signal.filtfilt(b, a, X[j, :, i])\n",
    "\n",
    "    # Print the shape of the filtered data\n",
    "    return filtered_data\n",
    "\n",
    "#____________________________________________________________________________________#\n",
    "\n",
    "def da_apply(X, functions, shape = False):\n",
    "    X_final = X.copy()\n",
    "\n",
    "    # Applys DA Augments in specified order\n",
    "    for func_dict in functions:\n",
    "        func = func_dict['func']\n",
    "        if(func_dict['params'] == None):\n",
    "            X_final = func(X_final)     \n",
    "        else:\n",
    "            params = func_dict['params']\n",
    "            X_final = func(X_final, *params)  \n",
    "\n",
    "    if(shape == True):\n",
    "        print(X_final.shape)\n",
    "\n",
    "    return X_final\n",
    "\n",
    "#func_dict = [{'func': normalize, 'params': [None]}]\n",
    "\n",
    "#func_dict = [{'func': baseline_drift, 'params': [0,0.05]}]\n",
    "\n",
    "# func_dict =[{'func': normalize, 'params': [None]},\n",
    "#             {'func': bandpass, 'params': [100, 0.5, 10, 3]}, # 100, 0.5, 10, 3\n",
    "#             {'func': baseline_drift, 'params': [0,0.075]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    func_dict =[{'func': normalize, 'params': [None]},  # Normalizing across the entire data set instead of by lead\n",
    "                {'func': baseline_drift, 'params': [0,0.075]}]  # I found that simulating a 0.075 drift works best\n",
    "\n",
    "    X_final = da_apply(X, func_dict) # If you want to experiment with data shape more, use a smaller data size. Subset X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((17418, 1000, 12), (17418,), (2183, 1000, 12), (2183,), (2198, 1000, 12), (2198,))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.device('/GPU:0'):\n",
    "    # Split data into train and test\n",
    "    test_fold =10\n",
    "    val_fold = 9\n",
    "\n",
    "    def tvt_split(X, Y, val_fold, test_fold, shape = False):\n",
    "        X_train = X[(Y.strat_fold != test_fold) & (Y.strat_fold != val_fold)]\n",
    "        y_train = Y[(Y.strat_fold != test_fold) & (Y.strat_fold != val_fold)].age\n",
    "\n",
    "        X_val = X[Y.strat_fold == val_fold]\n",
    "        y_val = Y[Y.strat_fold == val_fold].age\n",
    "\n",
    "        X_test = X[(Y.strat_fold == test_fold)]\n",
    "        y_test = Y[Y.strat_fold == test_fold].age\n",
    "\n",
    "        y_train = pd.get_dummies(y_train)\n",
    "        y_val = pd.get_dummies(y_val)\n",
    "        y_test = pd.get_dummies(y_test)\n",
    "\n",
    "        y_train = y_train.idxmax(axis = 1).to_numpy()\n",
    "        y_val = y_val.idxmax(axis = 1).to_numpy()\n",
    "        y_test = y_test.idxmax(axis = 1).to_numpy()\n",
    "\n",
    "        rX_train = X_train[(y_train < 89) & (y_train >= 18)] # Additional filtering of patients older than 89 and younger than 18\n",
    "        ry_train = y_train[(y_train < 89) & (y_train >= 18)]\n",
    "\n",
    "        rX_val = X_val[(y_val < 89) & (y_val >= 18)]\n",
    "        ry_val = y_val[(y_val < 89) & (y_val >= 18)]\n",
    "\n",
    "        rX_test = X_test[(y_test < 89) & (y_test >= 18)]\n",
    "        ry_test = y_test[(y_test < 89) & (y_test >= 18)]\n",
    "\n",
    "        if(shape == True):\n",
    "            print((X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape))\n",
    "\n",
    "        return rX_train, ry_train, rX_val, ry_val, rX_test, ry_test\n",
    "\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = tvt_split(X_final, Y, val_fold, test_fold, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_age_model_2 = tf.keras.models.load_model(\"../saved_models/100hz/age_models/model_1.h5\")\n",
    "ecg_sex_model_2 = tf.keras.models.load_model(\"../saved_models/100hz/sex_models/model_1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    age_temp = ecg_age_model_2(tf.convert_to_tensor(X_test))\n",
    "\n",
    "predicted_age_unsorted = np.asarray(tf.squeeze(age_temp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.377134660079085"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error,accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "mean_absolute_error(y_test, predicted_age_unsorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-Squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6122021713525028"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, predicted_age_unsorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sex Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((17418, 1000, 12), (17418,), (2183, 1000, 12), (2183,), (2198, 1000, 12), (2198,))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with tf.device('/CPU:0'):\n",
    "    # Split data into train and test\n",
    "    test_fold =10\n",
    "    val_fold = 9\n",
    "\n",
    "    def tvt_split(X, Y, val_fold, test_fold, shape = False):\n",
    "        X_train = X[(Y.strat_fold != test_fold) & (Y.strat_fold != val_fold)]\n",
    "        y_train = Y[(Y.strat_fold != test_fold) & (Y.strat_fold != val_fold)].sex\n",
    "\n",
    "        X_val = X[Y.strat_fold == val_fold]\n",
    "        y_val = Y[Y.strat_fold == val_fold].sex\n",
    "\n",
    "        X_test = X[(Y.strat_fold == test_fold)]\n",
    "        y_test = Y[Y.strat_fold == test_fold].sex\n",
    "\n",
    "        y_train = pd.get_dummies(y_train)\n",
    "        y_val = pd.get_dummies(y_val)\n",
    "        y_test = pd.get_dummies(y_test)\n",
    "\n",
    "        y_train = y_train.idxmax(axis = 1).to_numpy()\n",
    "        y_val = y_val.idxmax(axis = 1).to_numpy()\n",
    "        y_test = y_test.idxmax(axis = 1).to_numpy()\n",
    "\n",
    "        if(shape == True):\n",
    "            print((X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape))\n",
    "\n",
    "        return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "    sex_X_train, sex_y_train, sex_X_val, sex_y_val, sex_X_test, sex_y_test = tvt_split(X_final, Y, val_fold, test_fold, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    sex_temp = ecg_sex_model_2(tf.convert_to_tensor(sex_X_test))\n",
    "    predicted_sex_prob = np.asarray(tf.squeeze(sex_temp))\n",
    "    predicted_sex = np.where((np.squeeze(np.where(predicted_sex_prob >= 0.50, 1, 0))) == 1, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8861277587361359"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.sex.values\n",
    "predicted_sex\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(sex_y_test, predicted_sex_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saliency Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39m# Compute the gradients of the target class's score with respect to the input data\u001b[39;00m\n\u001b[0;32m     10\u001b[0m target_output \u001b[39m=\u001b[39m ecg_age_model_2\u001b[39m.\u001b[39moutput[:, target_class_index]\n\u001b[1;32m---> 11\u001b[0m grads \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39;49mgradients(target_output, ecg_age_model_2\u001b[39m.\u001b[39;49minput)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     12\u001b[0m grads_func \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39mfunction([ecg_age_model_2\u001b[39m.\u001b[39minput], [grads])\n\u001b[0;32m     14\u001b[0m \u001b[39m# Compute feature map weights by pooling the gradients along the time dimension\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\varun\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\backend.py:4664\u001b[0m, in \u001b[0;36mgradients\u001b[1;34m(loss, variables)\u001b[0m\n\u001b[0;32m   4652\u001b[0m \u001b[39m@keras_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mkeras.backend.gradients\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   4653\u001b[0m \u001b[39m@doc_controls\u001b[39m\u001b[39m.\u001b[39mdo_not_generate_docs\n\u001b[0;32m   4654\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgradients\u001b[39m(loss, variables):\n\u001b[0;32m   4655\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns the gradients of `loss` w.r.t. `variables`.\u001b[39;00m\n\u001b[0;32m   4656\u001b[0m \n\u001b[0;32m   4657\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4662\u001b[0m \u001b[39m        A gradients tensor.\u001b[39;00m\n\u001b[0;32m   4663\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4664\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mcompat\u001b[39m.\u001b[39;49mv1\u001b[39m.\u001b[39;49mgradients(\n\u001b[0;32m   4665\u001b[0m         loss, variables, colocate_gradients_with_ops\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m   4666\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\varun\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py:165\u001b[0m, in \u001b[0;36mgradients\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[39m# Creating the gradient graph for control flow mutates Operations.\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[39m# _mutation_lock ensures a Session.run call cannot occur between creating and\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39m# mutating new ops.\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[39mwith\u001b[39;00m ops\u001b[39m.\u001b[39mget_default_graph()\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m--> 165\u001b[0m   \u001b[39mreturn\u001b[39;00m gradients_util\u001b[39m.\u001b[39;49m_GradientsHelper(\n\u001b[0;32m    166\u001b[0m       ys, xs, grad_ys, name, colocate_gradients_with_ops,\n\u001b[0;32m    167\u001b[0m       gate_gradients, aggregation_method, stop_gradients,\n\u001b[0;32m    168\u001b[0m       unconnected_gradients)\n",
      "File \u001b[1;32mc:\\Users\\varun\\miniconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py:480\u001b[0m, in \u001b[0;36m_GradientsHelper\u001b[1;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Implementation of gradients().\"\"\"\u001b[39;00m\n\u001b[0;32m    479\u001b[0m \u001b[39mif\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 480\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mtf.gradients is not supported when eager execution \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    481\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mis enabled. Use tf.GradientTape instead.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    482\u001b[0m ys \u001b[39m=\u001b[39m variable_utils\u001b[39m.\u001b[39mconvert_variables_to_tensors(_AsList(ys))\n\u001b[0;32m    483\u001b[0m xs \u001b[39m=\u001b[39m [\n\u001b[0;32m    484\u001b[0m     x\u001b[39m.\u001b[39mhandle \u001b[39mif\u001b[39;00m resource_variable_ops\u001b[39m.\u001b[39mis_resource_variable(x) \u001b[39melse\u001b[39;00m x\n\u001b[0;32m    485\u001b[0m     \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m _AsList(xs)\n\u001b[0;32m    486\u001b[0m ]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead."
     ]
    }
   ],
   "source": [
    "from keras import backend\n",
    "# Choose a specific ECG sample for visualization\n",
    "sample_index = 0\n",
    "input_data = X_train[sample_index]  # Shape: (1, 1000, 12)\n",
    "\n",
    "# Obtain the target class (e.g., 'Male' or 'Female')\n",
    "target_class_index = 0  # Replace with the index of the target class in your model output\n",
    "\n",
    "# Compute the gradients of the target class's score with respect to the input data\n",
    "target_output = ecg_age_model_2.output[:, target_class_index]\n",
    "grads = backend.gradients(target_output, ecg_age_model_2.input)[0]\n",
    "grads_func = backend.function([ecg_age_model_2.input], [grads])\n",
    "\n",
    "# Compute feature map weights by pooling the gradients along the time dimension\n",
    "weights = np.mean(grads_func([input_data])[0], axis=1)\n",
    "\n",
    "# Generate the heatmap\n",
    "heatmap = np.maximum(np.sum(input_data * weights, axis=-1), 0)\n",
    "\n",
    "# Normalize the heatmap for visualization\n",
    "heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min())\n",
    "\n",
    "# Visualize the heatmap overlaid on the original ECG signal\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(X_train[sample_index])\n",
    "plt.imshow(heatmap, cmap='jet', alpha=0.5, extent=[0, 1000, np.min(X_train), np.max(X_train)])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
